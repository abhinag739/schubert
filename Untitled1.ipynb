{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\x1212\\\\Desktop'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "#https://drive.google.com/file/d/1qnQVK17DNVkU19MgVA4Vg88zRDvwCRXw/view\n",
    "from numpy.random import seed\n",
    "seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: music21 in c:\\users\\x1212\\anaconda3\\lib\\site-packages (5.7.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\x1212\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\x1212\\anaconda3\\lib\\site-packages (from keras) (3.12)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\x1212\\anaconda3\\lib\\site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\x1212\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\x1212\\anaconda3\\lib\\site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\x1212\\anaconda3\\lib\\site-packages (from keras) (2.7.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\x1212\\anaconda3\\lib\\site-packages (from keras) (1.17.4)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\x1212\\anaconda3\\lib\\site-packages (from keras) (1.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n",
      "music21: Certain music21 functions might need the optional package matplotlib;\n",
      "                  if you run into errors, install it by following the instructions at\n",
      "                  http://mit.edu/music21/doc/installing/installAdditional.html\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import some of the libraries created by MIT labs for understanding audio data\n",
    "\n",
    "!pip3 install music21\n",
    "!pip3 install keras\n",
    "from music21 import *\n",
    "\n",
    "#to process arrays, we are going to use the below modules\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#Random number generated\n",
    "import random\n",
    "\n",
    "#Keras for building deep learning models\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to read the MIDI files, the function will return a set of nodes and chords present in the musical file\n",
    "\n",
    "def read_midi(file):\n",
    "    notes=[]\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    #This part we will be parsing the midi file\n",
    "    midi = converter.parse(file)\n",
    "    #This part we will be grouping based on verious instruments\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "    \n",
    "    #now we are going to loop through all the instruments\n",
    "    for part in s2.parts:\n",
    "        #Now we can select elements of say only piano\n",
    "        if 'Piano' in str(part):\n",
    "            notes_to_parse = part.recurse()\n",
    "            #finding if a particular element is a note or a chord\n",
    "            for element in notes_to_parse:\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "                    \n",
    "    return notes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the midi files from the directory\n",
    "\n",
    "\n",
    "files=[i for i in os.listdir() if i.endswith(\".mid\")]\n",
    "\n",
    "#Loop and read through each midi file\n",
    "all_notes=[]\n",
    "for i in files:\n",
    "    all_notes.append(read_midi(i))\n",
    "    \n",
    "notes = [element for notes in all_notes for element in notes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the midi files from the directory\n",
    "\n",
    "no_of_timesteps = 128\n",
    "\n",
    "#number of unique notes\n",
    "n_vocab=len(set(notes))\n",
    "\n",
    "#All the uniqyue notes\n",
    "pitch = sorted(set(item for item in notes))\n",
    "\n",
    "#Assignign an unique value to every note\n",
    "note_to_int = dict((note, number) for number, note in enumerate(pitch))\n",
    "\n",
    "#Preparing the input and the output sequences\n",
    "X = []\n",
    "y = []\n",
    "for notes in all_notes:\n",
    "    for i in range(0, len(notes) - no_of_timesteps, 1):\n",
    "        input_ = notes[i:i + no_of_timesteps]\n",
    "        output = notes[i + no_of_timesteps]\n",
    "        X.append([note_to_int[note] for note in input_])\n",
    "        y.append(note_to_int[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolution CNN, the modelling has to be done in te form of shapes or features\n",
    "#so we ween to reshape the input according to the required shape\n",
    "\n",
    "#Reshaping\n",
    "X = np.reshape(X, (len(X), no_of_timesteps, 1))\n",
    "\n",
    "#Normalize the inputs\n",
    "X = X / float(n_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss-'sparse_categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The input would be a set of chords and notes because are generating music\n",
    "\n",
    "K.clear_session()\n",
    "def simple_wavenet():\n",
    "  no_of_kernels=64\n",
    "  num_of_blocks= int(np.sqrt(no_of_timesteps)) - 1   #no. of stacked conv1d layers\n",
    "\n",
    "  model = Sequential()\n",
    "  for i in range(num_of_blocks):\n",
    "    model.add(Conv1D(no_of_kernels,3,dilation_rate=(2**i),padding='causal',activation='relu'))\n",
    "  model.add(Conv1D(1, 1, activation='relu', padding='causal'))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(128, activation='relu'))\n",
    "  model.add(Dense(n_vocab, activation='softmax'))\n",
    "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to call a model we have to define a call back. Saved the model for every 50 epoch\n",
    "\n",
    "import keras\n",
    "mc = keras.callbacks.ModelCheckpoint('model{epoch:03d}.h5', save_weights_only=False, period = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "57856/63757 [==========================>...] - ETA: 1:01 - loss: 5.0522"
     ]
    }
   ],
   "source": [
    "#Instantiating and train the model with a batch size of 128\n",
    "model = simple_wavenet()\n",
    "model.fit(X,np.array(y), epochs=1, batch_size=128, callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_music(model,pitch,no_of_timesteps,pattern):\n",
    "    int_to_note = dict((number, note) for number,note in enumerate(pitch))\n",
    "    prediction_output = []\n",
    "    \n",
    "    #Generating 50 elements\n",
    "    \n",
    "    for note_index in range(50)\n",
    "    #Reshaping the input array before sending it as parameter to the model\n",
    "    input_ = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    \n",
    "    #Predicting the probability and chosing the maximum value\n",
    "    proba = model.predict(input_, verbose = 0)\n",
    "    index = np.argmax(proba)\n",
    "    \n",
    "    #Converting te integer back to an element for user\n",
    "    pred = int_to_note[index]\n",
    "    prediction_output.append(pred)\n",
    "    pattern = list(pattern)\n",
    "    pattern.append(index/float(n_vocab))\n",
    "    \n",
    "    #Leaving the first element value at index 0\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "    return prediction_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to convert the composed music into a MIDI file\n",
    "\n",
    "def convert_to_midi(prediction_output):\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    \n",
    "    #Now we can create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        #If pattern is a chord\n",
    "        if('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        #If pattern is a note then we do the following\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument=instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "            \n",
    "        #Now we will specify the duration between the two notes\n",
    "        offset+= 0.5\n",
    "        # offset += random.uniform(0.5,0.9)\n",
    "        \n",
    "        midi_stream = stream.Stream(output_notes)\n",
    "        midi_stream.write('midi', fp='music_1_fast-1.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# lets assume `model` is main model \n",
    "model_json = model.to_json()\n",
    "with open(\"model_in_json.json\", \"w\") as json_file:\n",
    "    json.dump(model_json, json_file)\n",
    "\n",
    "model_json.save_weights(\"C:\\\\Users\\\\x1212\\\\Desktop\\\\model300.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "\n",
    "with open('model_in_json.json','r') as f:\n",
    "    model_json = json.load(f)\n",
    "\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights('C:\\\\Users\\\\x1212\\\\Desktop\\\\model300.h5')\n",
    "\n",
    "\n",
    "start = np.random.randint(0, len(X)-1)\n",
    "pattern = X[start]\n",
    "\n",
    "#Generating and saving the music\n",
    "music = generate_music(model, pitch, no_of_timesteps,pattern)\n",
    "convert_to_midi(music)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
